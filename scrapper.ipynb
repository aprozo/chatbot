{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import getpass\n",
    "# Step 1: Start a session and login\n",
    "\n",
    "url=\"https://drupal.star.bnl.gov/STAR/theses?page=\"\n",
    "username = getpass.getpass(prompt='Please, enter username: ')\n",
    "password = getpass.getpass(prompt='Please, enter password: ')\n",
    "otp_code = getpass.getpass(prompt='Please, enter OneTimePass from Authenticator App: ')\n",
    "\n",
    "session = requests.Session()\n",
    "# This payload will need to be tailored to the specific site's login parameters\n",
    "login_page = session.get(url)\n",
    "soup = BeautifulSoup(login_page.text, 'html.parser')\n",
    "# Find form_build_id\n",
    "form_build_id = soup.find('input', {'name': 'form_build_id'}).get('value')\n",
    "# Step 2: Submit the login form\n",
    "login_data = {\n",
    "    'form_build_id': form_build_id,\n",
    "    'form_id': 'user_login_block',\n",
    "    'name': username,\n",
    "    'pass': password,\n",
    "    'gacode': otp_code,\n",
    "    'op': 'Log+in'\n",
    "}\n",
    "# Perform the login\n",
    "response = session.post(url, data=login_data)\n",
    "if \"Log out\" in response.text or response.status_code == 200:\n",
    "    print(\"Login successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://drupal.star.bnl.gov/STAR/theses?page=\"\n",
    "\n",
    "thesis_metadata = {}\n",
    "for page in range(0, 36):\n",
    "    pageurl = url + str(page)\n",
    "    page_response = session.get(pageurl)\n",
    "    soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "\n",
    "    # Define patterns to exclude unwanted links\n",
    "    exclude_keywords = [\"STAR Theses\", \"List\", \"Search\", \"Submit A Thesis\", \"first\", \"previous\", \"next\", \"last\"]\n",
    "    exclude_patterns = [\"/STAR/theses?\", \"/STAR/theses?page\"]\n",
    "\n",
    "    file_extensions = ('.pdf', '.gz', '.ps')\n",
    "\n",
    "    # Loop through all <a> tags to find thesis titles and file links\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        # Check if link contains a valid thesis entry by excluding unwanted entries nor\n",
    "        if ('theses' in link['href'] and not link['href'].endswith('.pdf') and not link['href'].endswith('.ps') and not link['href'].endswith('.gz') and\n",
    "            all(keyword not in link.get_text(strip=True) for keyword in exclude_keywords) and\n",
    "            all(pattern not in link['href'] for pattern in exclude_patterns)):\n",
    "            # This is a thesis title link\n",
    "            title = link.get_text(strip=True)\n",
    "            # Find the next <a> tag that might contain a file link ending with file extensions\n",
    "            file_link_tag = link.find_next('a', href=lambda href: href and  href.endswith(file_extensions))\n",
    "            \n",
    "            if file_link_tag:\n",
    "                file_link = file_link_tag['href']\n",
    "                pdf_filename =  file_link.split('/')[-1]\n",
    "            else:\n",
    "                file_link = None\n",
    "            \n",
    "        # Store the data in the thesis_data list\n",
    "            thesis_metadata[pdf_filename] = {\"Title\": [title], \"URL\": file_link}\n",
    "    \n",
    "# Output the collected metadata\n",
    "for data in thesis_metadata:\n",
    "    print (thesis_metadata[data])\n",
    "\n",
    "\n",
    "print (\"Number of theses found: \", len(thesis_metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Convert the dictionary to JSON format\n",
    "metadata_json = json.dumps(thesis_metadata, indent=4)\n",
    "\n",
    "# Optionally, save it to a file\n",
    "with open('metadata.json', 'w') as json_file:\n",
    "    json_file.write(metadata_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://drupal.star.bnl.gov/STAR/theses?page=\"\n",
    "\n",
    "for page in range(0, 36):\n",
    "    page_url = f\"{url}{page}\"\n",
    "\n",
    "    print (f\"Downloading page {page_url}\")\n",
    "    \n",
    "    page_response = session.get(page_url)\n",
    "    soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "    \n",
    "\n",
    "    pdf_links = []\n",
    "    download_folder=\"theses\"\n",
    "\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if link['href'].endswith('.pdf') or link['href'].endswith('.ps'):\n",
    "            pdf_links.append(link['href'])\n",
    "    print ('\\n'.join(pdf_links))\n",
    "\n",
    "    for pdf_link in pdf_links:\n",
    "        pdf_name = pdf_link.split(\"/\")[-1]\n",
    "        pdf_name = f\"{download_folder}/{pdf_name}\"\n",
    "        pdf_response = session.get(pdf_link)\n",
    "\n",
    "        with open(pdf_name, 'wb') as pdf_file:\n",
    "            pdf_file.write(pdf_response.content)\n",
    "            print(f\"Downloaded {pdf_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert .ps to .pdf\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define the folder containing the .ps files\n",
    "folder_path = 'theses'\n",
    "\n",
    "# List all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a .ps file\n",
    "    if file_name.endswith('.ps'):\n",
    "        # Construct the full file path\n",
    "        print (file_name)\n",
    "        ps_file = os.path.join(folder_path, file_name)\n",
    "        pdf_file = os.path.join(folder_path, file_name.replace('.ps', '.pdf'))\n",
    "        \n",
    "        # Convert the .ps file to .pdf using ps2pdf\n",
    "        subprocess.run(['ps2pdf', ps_file, pdf_file])\n",
    "print(\"Conversion complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
